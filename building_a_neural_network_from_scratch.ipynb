{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkA+qv2HTjK8dK7K+F+Cww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edieski/building_neural_network/blob/master/building_a_neural_network_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syms0o9XoLgS",
        "outputId": "5fa399f7-fadf-4966-ffd5-513f4f9f9486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "YU3-yxHsXpAO",
        "outputId": "d68af221-2c14-40af-83ad-8f433fa52602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 20 / 200\n",
            "45.653%\n",
            "Iteration: 40 / 200\n",
            "64.592%\n",
            "Iteration: 60 / 200\n",
            "73.258%\n",
            "Iteration: 80 / 200\n",
            "73.972%\n",
            "Iteration: 100 / 200\n",
            "77.555%\n",
            "Iteration: 120 / 200\n",
            "80.073%\n",
            "Iteration: 140 / 200\n",
            "81.932%\n",
            "Iteration: 160 / 200\n",
            "83.273%\n",
            "Iteration: 180 / 200\n",
            "84.343%\n",
            "Iteration: 200 / 200\n",
            "85.147%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a06a9b86dfb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/gdrive/My Drive/openclassrooms/trained_params.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdump_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/openclassrooms/trained_params.pkl'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z,0)\n",
        "\n",
        "def derivative_ReLU(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def softmax(Z):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    exp = np.exp(Z - np.max(Z)) #le np.max(Z) evite un overflow en diminuant le contenu de exp\n",
        "    return exp / exp.sum(axis=0)\n",
        "\n",
        "def init_params(size):\n",
        "    W1 = np.random.rand(10,size) - 0.5\n",
        "    b1 = np.random.rand(10,1) - 0.5\n",
        "    W2 = np.random.rand(10,10) - 0.5\n",
        "    b2 = np.random.rand(10,1) - 0.5\n",
        "    return W1,b1,W2,b2\n",
        "\n",
        "def forward_propagation(X,W1,b1,W2,b2):\n",
        "    Z1 = W1.dot(X) + b1 #10, m\n",
        "    A1 = ReLU(Z1) # 10,m\n",
        "    Z2 = W2.dot(A1) + b2 #10,m\n",
        "    A2 = softmax(Z2) #10,m\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def one_hot(Y):\n",
        "    ''' return an 0 vector with 1 only in the position correspondind to the value in Y'''\n",
        "    one_hot_Y = np.zeros((Y.max()+1,Y.size)) #si le chiffre le plus grand dans Y est 9 ca fait 10 lignes\n",
        "    one_hot_Y[Y,np.arange(Y.size)] = 1 # met un 1 en ligne Y[i] et en colonne i, change l'ordre mais pas le nombre\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_propagation(X, Y, A1, A2, W2, Z1, m):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = 2*(A2 - one_hot_Y) #10,m\n",
        "    dW2 = 1/m * (dZ2.dot(A1.T)) # 10 , 10\n",
        "    db2 = 1/m * np.sum(dZ2,1) # 10, 1\n",
        "    dZ1 = W2.T.dot(dZ2)*derivative_ReLU(Z1) # 10, m\n",
        "    dW1 = 1/m * (dZ1.dot(X.T)) #10, 784\n",
        "    db1 = 1/m * np.sum(dZ1,1) # 10, 1\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_params(alpha, W1, b1, W2, b2, dW1, db1, dW2, db2):\n",
        "    W1 -= alpha * dW1\n",
        "    b1 -= alpha * np.reshape(db1, (10,1))\n",
        "    W2 -= alpha * dW2\n",
        "    b2 -= alpha * np.reshape(db2, (10,1))\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    return np.sum(predictions == Y)/Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    size , m = X.shape\n",
        "\n",
        "    W1, b1, W2, b2 = init_params(size)\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
        "        dW1, db1, dW2, db2 = backward_propagation(X, Y, A1, A2, W2, Z1, m)\n",
        "\n",
        "        W1, b1, W2, b2 = update_params(alpha, W1, b1, W2, b2, dW1, db1, dW2, db2)   \n",
        "\n",
        "        if (i+1) % int(iterations/10) == 0:\n",
        "            print(f\"Iteration: {i+1} / {iterations}\")\n",
        "            prediction = get_predictions(A2)\n",
        "            print(f'{get_accuracy(prediction, Y):.3%}')\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def make_predictions(X, W1 ,b1, W2, b2):\n",
        "    _, _, _, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
        "    predictions = get_predictions(A2)\n",
        "    return predictions\n",
        "\n",
        "def show_prediction(index,X, Y, W1, b1, W2, b2):\n",
        "    # None => cree un nouvel axe de dimension 1, cela a pour effet de transposer X[:,index] qui un np.array de dimension 1 (ligne) et qui devient un vecteur (colonne)\n",
        "    #  ce qui correspond bien a ce qui est demande par make_predictions qui attend une matrice dont les colonnes sont les pixels de l'image, la on donne une seule colonne\n",
        "    vect_X = X[:, index,None]\n",
        "    prediction = make_predictions(vect_X, W1, b1, W2, b2)\n",
        "    label = Y[index]\n",
        "    print(\"Prediction: \", prediction)\n",
        "    print(\"Label: \", label)\n",
        "\n",
        "    current_image = vect_X.reshape((WIDTH, HEIGHT)) * SCALE_FACTOR\n",
        "\n",
        "    plt.gray()\n",
        "    plt.imshow(current_image, interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "SCALE_FACTOR = 255 # TRES IMPORTANT SINON OVERFLOW SUR EXP\n",
        "WIDTH = X_train.shape[1]\n",
        "HEIGHT = X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0],WIDTH*HEIGHT).T / SCALE_FACTOR\n",
        "X_test = X_test.reshape(X_test.shape[0],WIDTH*HEIGHT).T  / SCALE_FACTOR\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.15, 200)\n",
        "with open(r'/content/gdrive/My Drive/openclassrooms/trained_params.pkl',\"wb\") as dump_file:\n",
        "    pickle.dump((W1, b1, W2, b2),dump_file)\n",
        "\n",
        "with open(r'/content/gdrive/My Drive/openclassrooms/trained_params.pkl',\"rb\") as dump_file:\n",
        "    W1, b1, W2, b2=pickle.load(dump_file)\n",
        "show_prediction(0,X_test, Y_test, W1, b1, W2, b2)\n",
        "show_prediction(1,X_test, Y_test, W1, b1, W2, b2)\n",
        "show_prediction(2,X_test, Y_test, W1, b1, W2, b2)\n",
        "show_prediction(100,X_test, Y_test, W1, b1, W2, b2)\n",
        "show_prediction(200,X_test, Y_test, W1, b1, W2, b2)"
      ]
    }
  ]
}